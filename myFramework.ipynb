{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab3d00e",
   "metadata": {},
   "source": [
    "# ç‰¹å¾´ãƒ™ãƒ¼ã‚¹ã®çŸ¥è­˜è’¸ç•™ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯\n",
    "\n",
    "## ğŸ§ª ä»®èª¬\n",
    "ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®å‡¦ç†ã®æµã‚Œã‚’æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã«ä¼¼ã›ã‚‹ã“ã¨ã§ã€ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã¯æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«è¿‘ã¥ãã“ã¨ãŒã§ãã‚‹ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” ç‰¹å¾´\n",
    "\n",
    "- ä¸­é–“å±¤ã®ç‰¹å¾´è¡¨ç¾ã‚’æ´»ç”¨\n",
    "- CKAï¼ˆCentered Kernel Alignmentï¼‰ã«ã‚ˆã‚‹å±¤é–“é¡ä¼¼åº¦ã®è©•ä¾¡\n",
    "- æ§‹é€ çš„é¡ä¼¼æ€§ã®æ¨¡å€£ï¼šå‡¦ç†ã®æµã‚Œãã®ã‚‚ã®ã‚’æ¨¡å€£ã™ã‚‹\n",
    "  - ä¾‹ï¼šæ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒåºç›¤ã§å­¦ç¿’ã™ã‚‹ç‰¹å¾´ã¯ã€ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã‚‚åºç›¤ã§å­¦ç¿’ã™ã‚‹ã‚ˆã†ã«èª˜å°ã™ã‚‹\n",
    "- å±¤æ•°ã®é•ã„ã‚’å¸åå¯èƒ½ï¼šå±¤æ•°ãŒç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«é–“ã§ã‚‚è’¸ç•™ãŒå¯èƒ½\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ å®Ÿè£…æ‰‹é †\n",
    "\n",
    "1. æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™  \n",
    "   - å¤šãã®å ´åˆã€äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨\n",
    "\n",
    "2. æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã®å±¤é–“CKAè¨ˆç®—  \n",
    "   - å„å±¤ã®å‡ºåŠ›ã«å¯¾ã—ã¦CKAã‚’è¨ˆç®—ã—ã€é¡ä¼¼åº¦ã‚’è©•ä¾¡\n",
    "\n",
    "3. å±¤ã®ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°  \n",
    "   - æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã®å±¤ã‚’ CKA ã«åŸºã¥ã„ã¦ n ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†å‰²  \n",
    "   - ã‚°ãƒ«ãƒ¼ãƒ—ã¯é †ç•ªã‚’ä¿æŒã—ã€éš£æ¥ã™ã‚‹å±¤ã®ã¿åŒã˜ã‚°ãƒ«ãƒ¼ãƒ—ã«æ‰€å±å¯èƒ½\n",
    "\n",
    "4. ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®åˆ†å‰²  \n",
    "   - ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã‚‚åŒæ§˜ã« n ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†å‰²ï¼ˆå±¤æ•°ãŒç•°ãªã£ã¦ã„ã¦ã‚‚å‡ç­‰ã«åˆ†å‰²ï¼‰\n",
    "\n",
    "5. ã‚°ãƒ«ãƒ¼ãƒ—å¯¾å¿œä»˜ã‘  \n",
    "   - æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®å„ã‚°ãƒ«ãƒ¼ãƒ—ã‚’é †ç•ªã«å¯¾å¿œã•ã›ã€n Ã— n ã®å¯¾å¿œé–¢ä¿‚ã‚’æ§‹ç¯‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‰ æå¤±é–¢æ•°è¨­è¨ˆ\n",
    "\n",
    "- æ¯ãƒãƒƒãƒã§æå¤±ã‚’è¨ˆç®—\n",
    "- ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã¨æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã®å„å±¤ã®å‡ºåŠ›ã«å¯¾ã—ã¦ CKA ã‚’è¨ˆç®—\n",
    "- L_s Ã— L_t ã® CKA é¡ä¼¼åº¦ãƒãƒˆãƒªã‚¯ã‚¹ã‚’æ§‹ç¯‰  \n",
    "  - L_sï¼šç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®å±¤æ•°  \n",
    "  - L_tï¼šæ•™å¸«ãƒ¢ãƒ‡ãƒ«ã®å±¤æ•°\n",
    "\n",
    "- å¯¾è§’æˆåˆ†ã«å¯¾å¿œã™ã‚‹ n ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆGâ‚, Gâ‚‚, ..., Gâ‚™ï¼‰ã«æ³¨ç›®\n",
    "- å„ã‚°ãƒ«ãƒ¼ãƒ— Gáµ¢ ã®ä»£è¡¨å€¤ï¼ˆå¹³å‡ãªã©ï¼‰ã‚’ç®—å‡º â†’ CKA_Gáµ¢\n",
    "- æå¤±ã¨ã—ã¦ 1 - CKA_Gáµ¢ ã‚’è¨ˆç®—\n",
    "- å…¨ã‚°ãƒ«ãƒ¼ãƒ—ã®æå¤±ã‚’çµ±åˆï¼ˆåŠ é‡å¹³å‡ã€åˆè¨ˆãªã©ï¼‰ã—ã¦æœ€çµ‚æå¤±ã¨ã™ã‚‹\n",
    "\n",
    "---\n",
    "\n",
    "## âœ¨ ãƒ¡ãƒªãƒƒãƒˆ\n",
    "\n",
    "- å±¤æ•°ã®é•ã„ã‚’å¸åã—ãªãŒã‚‰ã€æ§‹é€ çš„ãªçŸ¥è­˜ã‚’åŠ¹æœçš„ã«è’¸ç•™å¯èƒ½\n",
    "- CKAã«ã‚ˆã‚Šã€å˜ãªã‚‹å‡ºåŠ›ã®ä¸€è‡´ã§ã¯ãªãç‰¹å¾´ç©ºé–“ã®é¡ä¼¼æ€§ã‚’é‡è¦–\n",
    "- å‡¦ç†ã®æµã‚Œã‚’æ¨¡å€£ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šæ·±ã„çŸ¥è­˜ã®è»¢ç§»ãŒå¯èƒ½\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cb5825",
   "metadata": {},
   "source": [
    "# å®Ÿè£…\n",
    "train_student.pyã‚’ãƒ™ãƒ¼ã‚¹ã«å®Ÿè£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581116c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "# import tensorboard_logger as tb_logger\n",
    "# å¤‰æ›´å¾Œ\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from models import model_dict\n",
    "from models.util import ConvReg, SelfA, SRRL, SimKD\n",
    "\n",
    "from dataset.cifar10 import get_cifar10_dataloaders, get_cifar10_dataloaders_sample\n",
    "from dataset.cifar100 import get_cifar100_dataloaders, get_cifar100_dataloaders_sample\n",
    "from dataset.imagenet import get_imagenet_dataloader,  get_dataloader_sample\n",
    "from dataset.cinic10 import get_cinic10_dataloaders, get_cinic10_dataloaders_sample\n",
    "# from dataset.FashionMNIST import get_FashionMNIST_dataloaders, get_FashionMNIST_dataloaders_sample\n",
    "# from dataset.imagenet_dali import get_dali_data_loader\n",
    "\n",
    "from helper.loops import train_distill as train, validate_vanilla, validate_distill\n",
    "from helper.util import save_dict_to_json, reduce_tensor, adjust_learning_rate\n",
    "\n",
    "from crd.criterion import CRDLoss\n",
    "from distiller_zoo import DistillKL, HintLoss, Attention, Similarity, VIDLoss, SemCKDLoss\n",
    "\n",
    "split_symbol = '~' if os.name == 'nt' else ':'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d743a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_teacher_name(model_path):\n",
    "    \"\"\"parse teacher name\"\"\"\n",
    "    directory = model_path.split('/')[-2]\n",
    "    pattern = ''.join(['S', split_symbol, '(.+)', '_T', split_symbol])\n",
    "    name_match = re.match(pattern, directory)\n",
    "    if name_match:\n",
    "        return name_match[1]\n",
    "    segments = directory.split('_')\n",
    "    if segments[0] == 'wrn':\n",
    "        return segments[0] + '_' + segments[1] + '_' + segments[2]\n",
    "    return segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b48e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_teacher(model_path, n_cls, gpu=None, opt=None):\n",
    "    print('==> loading teacher model')\n",
    "    model_t = get_teacher_name(model_path)\n",
    "    model = model_dict[model_t](num_classes=n_cls)\n",
    "    map_location = None if gpu is None else {'cuda:0': 'cuda:%d' % (gpu if opt.multiprocessing_distributed else 0)}\n",
    "    model.load_state_dict(torch.load(model_path, map_location=map_location)['model'])\n",
    "    print('==> done')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065b6a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_option():\n",
    "\n",
    "    parser = argparse.ArgumentParser('argument for training')\n",
    "    \n",
    "    # basic\n",
    "    parser.add_argument('--print_freq', type=int, default=200, help='print frequency')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, help='batch_size')\n",
    "    parser.add_argument('--num_workers', type=int, default=8, help='num of workers to use')\n",
    "    parser.add_argument('--epochs', type=int, default=240, help='number of training epochs')\n",
    "    parser.add_argument('--gpu_id', type=str, default='0', help='id(s) for CUDA_VISIBLE_DEVICES')\n",
    "\n",
    "    # optimization\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.05, help='learning rate')\n",
    "    parser.add_argument('--lr_decay_epochs', type=str, default='150,180,210', help='where to decay lr, can be a list')\n",
    "    parser.add_argument('--lr_decay_rate', type=float, default=0.1, help='decay rate for learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=5e-4, help='weight decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "\n",
    "    # dataset and model\n",
    "    parser.add_argument('--dataset', type=str, default='cifar10', choices=['cifar10', 'cifar100', 'imagenet', 'cinic10'], help='dataset')\n",
    "    parser.add_argument('--model_s', type=str, default='resnet8x4')\n",
    "    parser.add_argument('--path_t', type=str, default=None, help='teacher model snapshot')\n",
    "\n",
    "    # distillation\n",
    "    parser.add_argument('--trial', type=str, default='1', help='trial id')\n",
    "    parser.add_argument('--kd_T', type=float, default=4, help='temperature for KD distillation')\n",
    "    parser.add_argument('--distill', type=str, default='kd', choices=['kd', 'hint', 'attention', 'similarity', 'vid',\n",
    "                                                                      'crd', 'semckd','srrl', 'simkd'])\n",
    "    parser.add_argument('-c', '--cls', type=float, default=1.0, help='weight for classification')\n",
    "    parser.add_argument('-d', '--div', type=float, default=1.0, help='weight balance for KD')\n",
    "    parser.add_argument('-b', '--beta', type=float, default=0.0, help='weight balance for other losses')\n",
    "    parser.add_argument('-f', '--factor', type=int, default=2, help='factor size of SimKD')\n",
    "    parser.add_argument('-s', '--soft', type=float, default=1.0, help='attention scale of SemCKD')\n",
    "\n",
    "    # hint layer\n",
    "    parser.add_argument('--hint_layer', default=1, type=int, choices=[0, 1, 2, 3, 4])\n",
    "\n",
    "    # NCE distillation\n",
    "    parser.add_argument('--feat_dim', default=128, type=int, help='feature dimension')\n",
    "    parser.add_argument('--mode', default='exact', type=str, choices=['exact', 'relax'])\n",
    "    parser.add_argument('--nce_k', default=16384, type=int, help='number of negative samples for NCE')\n",
    "    parser.add_argument('--nce_t', default=0.07, type=float, help='temperature parameter for softmax')\n",
    "    parser.add_argument('--nce_m', default=0.5, type=float, help='momentum for non-parametric updates')\n",
    "\n",
    "    # multiprocessing\n",
    "    parser.add_argument('--dali', type=str, choices=['cpu', 'gpu'], default=None)\n",
    "    parser.add_argument('--multiprocessing-distributed', action='store_true',\n",
    "                    help='Use multi-processing distributed training to launch '\n",
    "                         'N processes per node, which has N GPUs. This is the '\n",
    "                         'fastest way to use PyTorch for either single node or '\n",
    "                         'multi node data parallel training')\n",
    "    parser.add_argument('--dist-url', default='tcp://127.0.0.1:23451', type=str,\n",
    "                    help='url used to set up distributed training')\n",
    "    parser.add_argument('--deterministic', action='store_true', help='Make results reproducible')\n",
    "    parser.add_argument('--skip-validation', action='store_true', help='Skip validation of teacher')\n",
    "    \n",
    "    opt = parser.parse_args()\n",
    "\n",
    "    # set different learning rates for these MobileNet/ShuffleNet models\n",
    "    if opt.model_s in ['MobileNetV2', 'MobileNetV2_1_0', 'ShuffleV1', 'ShuffleV2', 'ShuffleV2_1_5']:\n",
    "        opt.learning_rate = 0.01\n",
    "\n",
    "    # set the path of model and tensorboard\n",
    "    opt.model_path = './save/students/models'\n",
    "    opt.tb_path = './save/students/tensorboard'\n",
    "\n",
    "    iterations = opt.lr_decay_epochs.split(',')\n",
    "    opt.lr_decay_epochs = list([])\n",
    "    for it in iterations:\n",
    "        opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "    opt.model_t = get_teacher_name(opt.path_t)\n",
    "\n",
    "    model_name_template = split_symbol.join(['S', '{}_T', '{}_{}_{}_r', '{}_a', '{}_b', '{}_{}'])\n",
    "    opt.model_name = model_name_template.format(opt.model_s, opt.model_t, opt.dataset, opt.distill,\n",
    "                                                opt.cls, opt.div, opt.beta, opt.trial)\n",
    "\n",
    "    if opt.dali is not None:\n",
    "        opt.model_name += '_dali:' + opt.dali\n",
    "\n",
    "    opt.tb_folder = os.path.join(opt.tb_path, opt.model_name)\n",
    "    if not os.path.isdir(opt.tb_folder):\n",
    "        os.makedirs(opt.tb_folder)\n",
    "\n",
    "    opt.save_folder = os.path.join(opt.model_path, opt.model_name)\n",
    "    if not os.path.isdir(opt.save_folder):\n",
    "        os.makedirs(opt.save_folder)\n",
    "    \n",
    "    return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c6b51",
   "metadata": {},
   "source": [
    "### 1. æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™\n",
    "æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†ã“ã¨ã‚‚ã§ãã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9651bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# cmd = [\n",
    "#     \"python\", \"train_teacher.py\",\n",
    "#     \"--dataset\", \"cinic10\",\n",
    "#     \"--epochs\", \"240\",\n",
    "#     \"--trial\", \"0\",\n",
    "#     \"--model\", \"vgg8\"\n",
    "# ]\n",
    "\n",
    "# subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41dc216",
   "metadata": {},
   "source": [
    "### 2. æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã®å±¤é–“CKAè¨ˆç®—  \n",
    "   - å„å±¤ã®å‡ºåŠ›ã«å¯¾ã—ã¦CKAã‚’è¨ˆç®—ã—ã€é¡ä¼¼åº¦ã‚’è©•ä¾¡\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afac58b7",
   "metadata": {},
   "source": [
    "### 3. å±¤ã®ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°  \n",
    "   - æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã®å±¤ã‚’ CKA ã«åŸºã¥ã„ã¦ n ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†å‰²  \n",
    "   - ã‚°ãƒ«ãƒ¼ãƒ—ã¯é †ç•ªã‚’ä¿æŒã—ã€éš£æ¥ã™ã‚‹å±¤ã®ã¿åŒã˜ã‚°ãƒ«ãƒ¼ãƒ—ã«æ‰€å±å¯èƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a8bf7",
   "metadata": {},
   "source": [
    "### 4. ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®åˆ†å‰²  \n",
    "   - ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã‚‚åŒæ§˜ã« n ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†å‰²ï¼ˆå±¤æ•°ãŒç•°ãªã£ã¦ã„ã¦ã‚‚å‡ç­‰ã«åˆ†å‰²ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0346f8aa",
   "metadata": {},
   "source": [
    "### 5. ã‚°ãƒ«ãƒ¼ãƒ—å¯¾å¿œä»˜ã‘  \n",
    "   - æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®å„ã‚°ãƒ«ãƒ¼ãƒ—ã‚’é †ç•ªã«å¯¾å¿œã•ã›ã€n Ã— n ã®å¯¾å¿œé–¢ä¿‚ã‚’æ§‹ç¯‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
