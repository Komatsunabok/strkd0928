{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db834e4",
   "metadata": {},
   "source": [
    "# Pytorchのモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca49b59b",
   "metadata": {},
   "source": [
    "## 利用可能なモデルの一覧表示と取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "772ee154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available models\n",
    "import torchvision\n",
    "\n",
    "all_models = torchvision.models.list_models()\n",
    "classification_models = torchvision.models.list_models(module=torchvision.models)\n",
    "\n",
    "# # Initialize models\n",
    "# m1 = get_model(\"mobilenet_v3_large\", weights=None)\n",
    "# m2 = get_model(\"quantized_mobilenet_v3_large\", weights=\"DEFAULT\")\n",
    "\n",
    "# # Fetch weights\n",
    "# weights = get_weight(\"MobileNet_V3_Large_QuantizedWeights.DEFAULT\")\n",
    "# assert weights == MobileNet_V3_Large_QuantizedWeights.DEFAULT\n",
    "\n",
    "# weights_enum = get_model_weights(\"quantized_mobilenet_v3_large\")\n",
    "# assert weights_enum == MobileNet_V3_Large_QuantizedWeights\n",
    "\n",
    "# weights_enum2 = get_model_weights(torchvision.models.quantization.mobilenet_v3_large)\n",
    "# assert weights_enum == weights_enum2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ded547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd300_vgg16\n",
      "vgg11\n",
      "vgg11_bn\n",
      "vgg13\n",
      "vgg13_bn\n",
      "vgg16\n",
      "vgg16_bn\n",
      "vgg19\n",
      "vgg19_bn\n"
     ]
    }
   ],
   "source": [
    "model = \"vgg\"\n",
    "for i in all_models:\n",
    "    if model in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40ae4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg11\n",
      "vgg11_bn\n",
      "vgg13\n",
      "vgg13_bn\n",
      "vgg16\n",
      "vgg16_bn\n",
      "vgg19\n",
      "vgg19_bn\n"
     ]
    }
   ],
   "source": [
    "model = \"vgg\"\n",
    "for i in classification_models:\n",
    "    if model in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06089e76",
   "metadata": {},
   "source": [
    "## モデルの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8479c0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.vgg16_bn(weights=models.VGG16_BN_Weights.IMAGENET1K_V1)\n",
    "model_name = \"vgg16_bn\"\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f94088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "torch.save(model.state_dict(), os.path.join(\"save\", \"download\", model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f988346",
   "metadata": {},
   "source": [
    "# モデル削除・移動"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a6e4c1",
   "metadata": {},
   "source": [
    "## モデル一覧表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4b2b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"vgg16_bn-cifar100-trial_0-epochs_240-bs_64-20251006\",\n",
      "\"vgg13_bn-cifar100-trial_0-epochs_1-bs_64-20251006\",\n",
      "\"vgg16_bn-ft-cifar100-trial_0-epochs_240-bs_64-20251006\",\n",
      "\"vgg16-fe-cifar100-trial_0-epochs_1-bs_64-20251005\",\n",
      "\"vgg16_bn-fe-cifar100-trial_0-epochs_1-bs_64-20251005\",\n",
      "\"vgg16_bn-cifar100-trial_0-epochs_1-bs_64-20251006\",\n",
      "\"vgg16_bn-scratch-cifar100-trial_0-epochs_240-bs_64-20251005\",\n",
      "\"vgg16_bn-fe-cifar100-trial_0-epochs_240-bs_64-20251005\",\n",
      "\"vgg16_bn-scratch-cifar100-trial_0-epochs_1-bs_64-20251005\",\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "target = \"teachers\"\n",
    "\n",
    "# ==== 基本ディレクトリ ====\n",
    "base_dir = os.path.join(\"save\", target)\n",
    "model_dir = os.path.join(base_dir, \"models\")\n",
    "tb_dir = os.path.join(base_dir, \"tensorboard\")\n",
    "\n",
    "# ==== 両方に存在する名前を取得（ファイルでもフォルダでもOK） ====\n",
    "common_items = set(os.listdir(model_dir)) & set(os.listdir(tb_dir))\n",
    "\n",
    "for i in common_items:\n",
    "    print(\"\\\"\", i, \"\\\"\", \",\", sep=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974079d1",
   "metadata": {},
   "source": [
    "## モデル削除or移動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71b5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving: ..\\save\\teachers\\models\\vgg13_vanilla_cifar10_trial_0_epochs_240_bs_64_opt_sgd_lr_she_cosine_lr_0.001 and ..\\save\\teachers\\tensorboard\\vgg13_vanilla_cifar10_trial_0_epochs_240_bs_64_opt_sgd_lr_she_cosine_lr_0.001\n",
      "Moving: ..\\save\\teachers\\models\\vgg8_vanilla_cinic10_trial_0_epochs_240_bs_64 and ..\\save\\teachers\\tensorboard\\vgg8_vanilla_cinic10_trial_0_epochs_240_bs_64\n",
      "Moving: ..\\save\\teachers\\models\\vgg13_vanilla_cifar10_trial_0_epochs_240_bs_64_opt_sgd_lr_she_cosine_lr_0.01 and ..\\save\\teachers\\tensorboard\\vgg13_vanilla_cifar10_trial_0_epochs_240_bs_64_opt_sgd_lr_she_cosine_lr_0.01\n",
      "Moving: ..\\save\\teachers\\models\\vgg13_vanilla_cifar10_trial_0_epochs_240_bs_64_opt_sgd_lr_she_cosine_lr_0.005 and ..\\save\\teachers\\tensorboard\\vgg13_vanilla_cifar10_trial_0_epochs_240_bs_64_opt_sgd_lr_she_cosine_lr_0.005\n",
      "Moving: ..\\save\\teachers\\models\\vgg13_vanilla_cifar10_trial_0_epochs_240_bs_64 and ..\\save\\teachers\\tensorboard\\vgg13_vanilla_cifar10_trial_0_epochs_240_bs_64\n",
      "Moving: ..\\save\\teachers\\models\\vgg13_vanilla_cifar10_trial_0_epochs_240_bs_64_opt_adam_lr_she_constant_lr_0.01 and ..\\save\\teachers\\tensorboard\\vgg13_vanilla_cifar10_trial_0_epochs_240_bs_64_opt_adam_lr_she_constant_lr_0.01\n",
      "Moving: ..\\save\\teachers\\models\\vgg13_vanilla_cifar10_trial_0_epochs_240_bs_64_opt_adam_lr_she_cosine and ..\\save\\teachers\\tensorboard\\vgg13_vanilla_cifar10_trial_0_epochs_240_bs_64_opt_adam_lr_she_cosine\n",
      "Moving: ..\\save\\teachers\\models\\vgg13_vanilla_cifar100_trial_0_epochs_240_bs_64 and ..\\save\\teachers\\tensorboard\\vgg13_vanilla_cifar100_trial_0_epochs_240_bs_64\n",
      "Moving: ..\\save\\teachers\\models\\vgg13_vanilla_cifar100_trial_0_epochs_240_bs_64_opt_adam_lr_she_cosine_lr_0.01 and ..\\save\\teachers\\tensorboard\\vgg13_vanilla_cifar100_trial_0_epochs_240_bs_64_opt_adam_lr_she_cosine_lr_0.01\n",
      "Moving: ..\\save\\teachers\\models\\vgg13_vanilla_cifar10_trial_0_epochs_240_bs_64_opt_sgd_lr_she_cosine and ..\\save\\teachers\\tensorboard\\vgg13_vanilla_cifar10_trial_0_epochs_240_bs_64_opt_sgd_lr_she_cosine\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# ==== モデル名 ==== \n",
    "names = [\"vgg16_bn-cifar100-trial_0-epochs_1-bs_64-20251006\",\n",
    "         \n",
    "]\n",
    "\n",
    "# ==== オプション設定 ====\n",
    "mode = \"move\"   # \"delete\" または \"move\"\n",
    "dest = os.path.join(\"..\", \"bin\", \"archive\", target)  # mode=\"move\" のとき移動先を指定\n",
    "\n",
    "if mode == \"move\":\n",
    "    if not dest:\n",
    "        raise ValueError(\"mode='move' のときは dest を指定してください\")\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "for name in names:\n",
    "    m_path = os.path.join(model_dir, name)\n",
    "    t_path = os.path.join(tb_dir, name)\n",
    "\n",
    "    if os.path.exists(m_path) and os.path.exists(t_path):\n",
    "        if mode == \"delete\":\n",
    "            print(f\"Deleting: {m_path} and {t_path}\")\n",
    "            # ファイルかフォルダかで削除方法を分岐\n",
    "            if os.path.isdir(m_path):\n",
    "                shutil.rmtree(m_path)\n",
    "            else:\n",
    "                os.remove(m_path)\n",
    "\n",
    "            if os.path.isdir(t_path):\n",
    "                shutil.rmtree(t_path)\n",
    "            else:\n",
    "                os.remove(t_path)\n",
    "\n",
    "        elif mode == \"move\":\n",
    "            print(f\"Moving: {m_path} and {t_path}\")\n",
    "            shutil.move(m_path, os.path.join(dest, f\"model_{name}\"))\n",
    "            shutil.move(t_path, os.path.join(dest, f\"tensorboard_{name}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538885aa",
   "metadata": {},
   "source": [
    "# .pthの中身を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9748db97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in first file: dict_keys(['epoch', 'best_acc', 'model'])\n",
      "File size: 37711138 bytes\n",
      "Keys in second file: dict_keys(['epoch', 'best_acc', 'model'])\n",
      "File size: 37711366 bytes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# 1つ目のファイル\n",
    "file_path1 = r\"..\\ckad0818\\save\\teachers_VGG13\\models\\vgg13-vanilla-cifar10-trial_0-epochs_240-bs_64-20250903\\vgg13_best.pth\"\n",
    "state1 = torch.load(file_path1, map_location=\"cpu\")\n",
    "print(\"Keys in first file:\", state1.keys())\n",
    "size1 = os.path.getsize(file_path1)\n",
    "print(\"File size:\", size1, \"bytes\")\n",
    "# print(\"Keys in state_dict:\")\n",
    "# for k, v in state1['model'].items():\n",
    "#     print(f\"{k}: {tuple(v.shape) if hasattr(v, 'shape') else 'scalar'} - dtype: {v.dtype} - size: {v.numel()*v.element_size()/1024/1024:.2f} MB\")\n",
    "\n",
    "\n",
    "# 2つ目のファイル\n",
    "file_path2 = r\"save\\teachers\\models\\vgg13_bn-cifar10-trial_0-epochs_1-bs_64-20251010_115552\\vgg13_bn_best.pth\"\n",
    "state2 = torch.load(file_path2, map_location=\"cpu\")\n",
    "print(\"Keys in second file:\", state2.keys())\n",
    "size2 = os.path.getsize(file_path2)\n",
    "print(\"File size:\", size2, \"bytes\")\n",
    "# print(\"Keys in state_dict:\")\n",
    "# for k, v in state2['model'].items():\n",
    "#     print(f\"{k}: {tuple(v.shape) if hasattr(v, 'shape') else 'scalar'} - dtype: {v.dtype} - size: {v.numel()*v.element_size()/1024/1024:.2f} MB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87074887",
   "metadata": {},
   "source": [
    "# モデルのサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f87e021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (block0): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block4): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool4): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (classifier): Linear(in_features=512, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from models import model_dict\n",
    "n_cls = {\n",
    "    'cifar10':10,\n",
    "    'cifar100': 100,\n",
    "    'imagenet': 1000,\n",
    "    'cinic10': 10\n",
    "}\n",
    "model = model_dict[\"vgg16_bn\"](num_classes=n_cls['cifar100'])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c924b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
